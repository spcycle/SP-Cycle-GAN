import torch
from torch.utils.data import Dataset,DataLoader,random_split
import torchvision
import os
from PIL import Image
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from dataset import *
import numpy as np
from tqdm import tqdm
import numpy as np
import sys
import logging
from pathlib import Path
from utils.dice_score import dice_loss
from evaluate import evaluate
from unet import UNet
from torch import optim
import wandb
from torch.utils.data import WeightedRandomSampler
import segmentation_models_pytorch as smp
import albumentations as A
import matplotlib.pyplot as plt
from utils.logging_lr import Logger,LambdaLR
import time
import Attention_Unet_Pytorch.models.unet as unet


## Set original_seg_dir to the directory of the translated image and label patches generated by running generate_patches_STAREandDRIVE.py.
## This code will take those translated patches and train Attention U-Net models for final Unsupevised DA testing on the unseen target domain.
## Set original_dir_checkpoint to where you want the UNet models saved. Baseline file can be trained by specifying folder name values to be:
## "S2D_Baseline" for the STARE to DRIVE problem, or "D2S_Baseline" for DRIVE to STARE.

original_seg_dir = r""
original_dir_checkpoint = r""

folders = os.listdir(original_seg_dir)

for file in folders:
    torch.cuda.empty_cache()
    torch.manual_seed(42)
    seg_dir = os.path.join(original_seg_dir,file)
    dir_checkpoint = os.path.join(original_dir_checkpoint,file)
    if os.path.isdir(dir_checkpoint):
        continue

    if not os.path.isdir(dir_checkpoint):
        os.mkdir(dir_checkpoint)

    transforms_img = [
                    transforms.ToTensor(),
                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]

    transforms_mask = [ 
                    transforms.ToTensor()]
    if "S2D_Baseline" in file:
        clahe = False
        if "clahe" in file:
            clahe = True
        crop_size = 384
        resize_size = 512
        dataset = STARE_Baseline(transform_image = transforms_img, transform_mask = transforms_mask, clahe = clahe, crop_size = crop_size, resize_size = resize_size)

    if "D2S_Baseline" in file:
        clahe = False
        if "clahe" in file:
            clahe = True
        crop_size = 384
        resize_size = 512
        dataset = DRIVE_Baseline(transform_image = transforms_img, transform_mask = transforms_mask, clahe = clahe, crop_size = crop_size, resize_size = resize_size)
     
    else:
        clahe = False
        print("Loading patches and masks")    
        dataset = SegGAN_Dataset(seg_dir, transform_image = transforms_img, transform_mask = transforms_mask, clahe = clahe)

    batch_size = 4

    tversky = smp.losses.TverskyLoss(mode = 'binary',eps=1e-07,alpha = 0.3, beta = 0.7,smooth=0.0)
    loader_args = dict(batch_size=batch_size, num_workers=0, pin_memory=True)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logging.info(f'Using device {device}')


    net = unet.Unet(64, attention=True).cuda()
    learning_rate = 0.001
    epochs = 120
    amp = True
    optimizer = optim.Adam(net.parameters(),lr=learning_rate)
    lr_sched = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=LambdaLR(epochs, 0, 100).step)
    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)
    criterion = nn.BCEWithLogitsLoss()
    global_step = 0
    logger = Logger(epochs, len(dataloader))

    net.train()
    for epoch in range(0, epochs):
        for i, batch in enumerate(dataloader):
            optimizer.zero_grad()
            
            image = batch['image'].to(device='cuda')
            mask_true = batch['label'].to(device='cuda').float()
            pred_mask,_ = net(image)
            loss = torch.pow(tversky(pred_mask,mask_true),3/4)
            loss.backward()
            optimizer.step()
            logger.log(losses={'loss_G': loss}, 
                images={'image': image[0,:,:,:],'pred_mask': F.sigmoid(pred_mask[0,:,:,:]), 'true_mask': mask_true[0,:,:,:]},epoch=epoch)
            
        lr_sched.step()
        if (epoch+1)%5 == 0:
            torch.save(net.state_dict(), os.path.join(dir_checkpoint,('UNet_epoch_%s.pth'%str(epoch+1))))

